{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00cd3ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot-ng in c:\\users\\kitty\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\users\\kitty\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pydot-ng) (2.4.7)\n",
      "Requirement already satisfied: pydotplus in c:\\users\\kitty\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\users\\kitty\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pydotplus) (2.4.7)\n",
      "Requirement already satisfied: graphviz in c:\\users\\kitty\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.16)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "!pip install pydotplus\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02965dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from tkinter import filedialog\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07189268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3151db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da44570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addaptive_histogram(img,clahe):\n",
    "        H_list = [];\n",
    "        if len(img.shape) == 3:\n",
    "            r, g, b = cv2.split(img)\n",
    "            lit = [r, g, b]\n",
    "            for img1 in lit:          \n",
    "                equ = clahe.apply(img1)\n",
    "                H_list.append(equ)\n",
    "            H_img = cv2.merge((H_list[0], H_list[1], H_list[2]))\n",
    "        else:\n",
    "            H_img = clahe.apply(img)\n",
    "            \n",
    "        return H_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eeefbe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertion over union ( for merging overlapped segmented )\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5ca9088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def U_net(modelPath, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):\n",
    "    # Build U-Net model\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = Lambda(lambda x: x / 255) (inputs)\n",
    "    \n",
    "    c1 = Conv2D(16, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (s)\n",
    "    c1 = Dropout(0.1) (c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    \n",
    "    c2 = Conv2D(32, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (p1)\n",
    "    c2 = Dropout(0.1) (c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    \n",
    "    c3 = Conv2D(64, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (p2)\n",
    "    c3 = Dropout(0.2) (c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    \n",
    "    c4 = Conv2D(128, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (p3)\n",
    "    c4 = Dropout(0.2) (c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (c4)\n",
    "    p4 = MaxPooling2D(pool_size = (2, 2)) (c4)\n",
    "    \n",
    "    c5 = Conv2D(256, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (p4)\n",
    "    c5 = Dropout(0.3) (c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (c5)\n",
    "    \n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides = (2, 2), padding = 'same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation = 'elu', kernel_initializer='he_normal', padding = 'same') (u6)\n",
    "    c6 = Dropout(0.2) (c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation = 'elu', kernel_initializer='he_normal', padding = 'same') (c6)\n",
    "    \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides = (2, 2), padding = 'same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (u7)\n",
    "    c7 = Dropout(0.2) (c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (c7)\n",
    "    \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides = (2, 2), padding = 'same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (u8)\n",
    "    c8 = Dropout(0.1) (c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (c8)\n",
    "    \n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides = (2, 2), padding = 'same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis = 3)\n",
    "    c9 = Conv2D(16, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (u9)\n",
    "    c9 = Dropout(0.1) (c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation = 'elu', kernel_initializer = 'he_normal', padding = 'same') (c9)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation = 'sigmoid') (c9)\n",
    "    \n",
    "    model = Model(inputs = [inputs], outputs = [outputs])\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = [mean_iou])\n",
    "    model.load_weights(modelPath)\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36def85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, imagePath, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):\n",
    "    img=cv2.imread(imagePath,0)\n",
    "    maskl = cv2.threshold(img, 190,255, cv2.THRESH_BINARY)\n",
    "    img=np.expand_dims(img,axis = -1)\n",
    "    x_test= np.zeros((1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype = np.uint8)\n",
    "    #testimg = resize(img,(self.IMG_HEIGHT,self.IMG_WIDTH),mode = 'constant',preserve_range = True)\n",
    "    x_test[0] = img\n",
    "    preds_test = model.predict(x_test, verbose = 1)\n",
    "    #print(preds_test)\n",
    "    preds_test = ((preds_test >= 0.5))\n",
    "    mask1 = np.uint8(preds_test[0])\n",
    "    mask1[mask1 == 1] = 255\n",
    "    #cv2.imshow('', maskl[1])\n",
    "    #cv2.waitKey(0)\n",
    "    return x_test[0], maskl[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e1794dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 512\n",
    "IMG_WIDTH = 512\n",
    "IMG_CHANNELS = 3\n",
    "modelPath = 'model-dsbowl2018-1.h5'\n",
    "\n",
    "trained_model = U_net(modelPath, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de965813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ errors --------------------------\n",
    "# plot_model(trained_model, show_shapes = True)\n",
    "# loss = trained_model.history['loss']\n",
    "# val_loss = trained_model.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fe6005d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit = 2.0, tileGridSize = (8,8))\n",
    "# Select Image\n",
    "# filename = filedialog.askopenfilename(title = 'open')\n",
    "# Read Image From Directory\n",
    "img1 = cv2.imread(\"hurricane-florence_00000019_pre_disaster.png\")\n",
    "H_img1 = addaptive_histogram(img1, clahe)\n",
    "test_image_name1 = \"pre_disaster.png\"\n",
    "H_img1 = cv2.resize(H_img1, (512, 512))\n",
    "cv2.imwrite(test_image_name1, H_img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f63c82fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Image\n",
    "# filename = filedialog.askopenfilename(title='open')\n",
    "# Read Image From Directory\n",
    "img2 = cv2.imread(\"hurricane-florence_00000019_post_disaster.png\")\n",
    "H_img2 = addaptive_histogram(img2,clahe)\n",
    "test_image_name2 = \"post_disaster.png\"\n",
    "H_img2 = cv2.resize(H_img2,(512,512))\n",
    "cv2.imwrite(test_image_name2, H_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f594fc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 531ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n"
     ]
    }
   ],
   "source": [
    "testimg, mask1 = prediction(trained_model, test_image_name1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "testimg, mask2 = prediction(trained_model, test_image_name2, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "275d953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_image = np.concatenate((cv2.resize(img1,(512, 512)), cv2.resize(img2,(512, 512))), axis = 1)\n",
    "Enhance_Image = np.concatenate((H_img1, H_img2), axis=1)\n",
    "segmented_Image = np.concatenate((cv2.resize(mask1,(512, 512)), cv2.resize(mask2,(512, 512))), axis = 1)\n",
    "mask1 = np.array(mask1)\n",
    "mask2 = np.array(mask2)\n",
    "\n",
    "bw_image = np.uint8(((mask1-mask2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c683d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kitty\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "mark_damage_region = cv2.merge((bw_image, bw_image, bw_image))\n",
    "\n",
    "plt.imshow(Input_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32a10155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mark_damage_region = cv2.merge((bw_image, bw_image, bw_image))\n",
    "#Visualization\n",
    "cv2.imshow('Input Image', Input_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Pre_processed Image', Enhance_Image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Segmented Image', segmented_Image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('Dmaged Region', mark_damage_region)\n",
    "cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccd244c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_image[bw_image >= 1] = 1\n",
    "bw_image = bw_image.flatten();\n",
    "Total_change= np.sum(bw_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab2a5ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1=mask1.flatten()\n",
    "mask1[mask1 >=1 ] = 1\n",
    "Pre_unchangedpixel = np.sum(mask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c768e82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Percent of Damage in segmented Region  70.65513703649421  %\n",
      "Total Percent of Damage in completed Image  9.1949462890625  %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_damage = (Total_change/(Pre_unchangedpixel))*100\n",
    "print(\"Total Percent of Damage in segmented Region \", percentage_damage,' %')\n",
    "\n",
    "#percentage_damage = (Total_change/(512*512))*100\n",
    "#print(\"Total Percent of Damage in completed Image \", percentage_damage,' %')\n",
    "\n",
    "cv2.imwrite(\"resized_mask.png\",bw_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c161780a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
