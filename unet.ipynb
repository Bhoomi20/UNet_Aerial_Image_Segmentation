{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import datetime\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Concatenate, UpSampling2D, BatchNormalization\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded layers ---> conv\n",
    "# maxpooled layers ---> pool\n",
    "def encoder(layer, filters, kernel_size = (3,3), padding = \"same\", strides = 1):\n",
    "    \n",
    "    conv = Conv2D(filters, kernel_size, padding = padding, strides = strides, activation = \"relu\")(layer)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Dropout(0.2)(conv)\n",
    "    \n",
    "    conv = Conv2D(filters, kernel_size, padding = padding, strides = strides, activation = \"relu\")(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Dropout(0.2)(conv)    \n",
    "    \n",
    "    pool = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid')(conv)\n",
    "    \n",
    "    return conv, pool\n",
    "\n",
    "\n",
    "\n",
    "def bottleneck(layer, filters, kernel_size = (3,3), padding = \"same\", strides = 1):\n",
    "    \n",
    "    conv = Conv2D(filters, kernel_size, padding = padding, strides = strides, activation = \"relu\")(layer)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Dropout(0.2)(conv)\n",
    "    \n",
    "    conv = Conv2D(filters, kernel_size, padding = padding, strides = strides, activation = \"relu\")(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Dropout(0.2)(conv)\n",
    "    \n",
    "    return conv\n",
    "\n",
    "\n",
    "\n",
    "# decoded layers ---> conv\n",
    "def decoder(concatenated_layer, encoded_layer, filters, kernel_size = (3,3), padding = \"same\", strides = 1):\n",
    "    \n",
    "    up = UpSampling2D((2,2))(concatenated_layer)\n",
    "    concat = Concatenate()([up,encoded_layer])\n",
    "    \n",
    "    conv = Conv2D(filters, kernel_size, padding = padding, strides = strides, activation = \"relu\")(concat)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    \n",
    "    conv = Conv2D(filters, kernel_size, padding = padding, strides = strides, activation = \"relu\")(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    \n",
    "    return conv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unet():\n",
    "    \n",
    "    filter_size = 16\n",
    "    depth = 4\n",
    "    \n",
    "    inputs = Input(shape = (image_size, image_size, 3))\n",
    "    \n",
    "    p0 = inputs\n",
    "    layers = []\n",
    "    temp = p0\n",
    "    \n",
    "    for i in range(depth):\n",
    "        conv, pooled_filter = encoder(temp, filter_size)\n",
    "        layers.append(conv)\n",
    "        \n",
    "        temp = pooled_filter\n",
    "        filter_size *= 2\n",
    "    \n",
    "    bn = bottleneck(temp, filter_size)\n",
    "    temp = bn\n",
    "    \n",
    "    for layer in layers[::-1]:\n",
    "        up = decoder(temp, layer, filter_size/2)\n",
    "        temp = up\n",
    "        \n",
    "    outputs = Conv2D(1, (1,1), padding = \"same\", activation = \"sigmoid\")(temp)\n",
    "    del temp\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.metrics.BinaryCrossentropy()\n",
    "metrics = tf.metrics.Accuracy()\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
